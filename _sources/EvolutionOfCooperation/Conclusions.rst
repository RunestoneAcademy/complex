Conclusions
-----------
Axelrod’s tournaments suggest a possible resolution to the problem of altruism: maybe being nice, but not *too* nice, is adaptive. But the strategies in the original tournaments were designed by people, not evolution, and the distribution of strategies did not change over the course of the tournaments.

So that raises a question: strategies like TFT might do well in a fixed population of human-designed strategies, but can they evolve? In other words, can they appear in a population through mutation, compete successfully with their ancestors, and resist invasion by their descendants?

The simulations in this chapter suggest:

- Populations of defectors are vulnerable to invasion by nicer strategies.
- Populations that are too nice are vulnerable to invasion by defectors.
- As a result, the average level of niceness oscillates, but the average amount of niceness is generally high, and the average level of fitness is generally closer to a utopia of cooperation than to a dystopia of defection.
- TFT, which was a successful strategy in Alexrod’s tournaments, does not seem to be a specially optimal strategy in an evolving population. In fact, there is probably no stable optimal strategy.
- Some degree of retaliation may be adaptive, but it might not be necessary for all agents to retaliate. If there is enough retaliation in the population as a whole, that might be enough to prevent invasion by defectors.

Obviously, the agents in these simulations are simple, and the Prisoner’s Dilemma is a highly abstract model of a limited range of social interactions. Nevertheless, the results in this chapter provide some insight into human nature. Maybe our inclinations toward cooperation, retaliation, and forgiveness are innate, at least in part. These characteristics are a result of how our brains are wired, which is controlled by our genes, at least in part. And maybe our genes build our brains that way because over the history of human evolution, genes for less altruistic brains were less likely to propagate.

Maybe that’s why selfish genes build altruistic brains.

.. mchoice:: q_13.9
    :answer_b: always cooperate 
    :answer_a: always defect
    :answer_c: TFT
    :answer_d: Oppisite of what was done the done the prior round.
    :correct: b
    :feedback_b: Correct!
    :feedback_a: Incorrect, look again at what the simulations went toward.
    :feedback_c: Incorrect, this was discribed as not optimal.
    :feedback_d: Incorrect, this would not work as the society tends to be nice.
    
    As a population how did the agents tend to lean as a strategy?