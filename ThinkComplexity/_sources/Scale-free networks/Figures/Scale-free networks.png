<!DOCTYPE html>
<!-- saved from url=(0066)http://greenteapress.com/complexity2/html/thinkcomplexity2005.html -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">

<meta name="generator" content="hevea 2.30">
<link rel="stylesheet" type="text/css" href="./Scale-free networks_files/thinkcomplexity2.css">
<title>Scale-free networks</title>
</head>
<body>
<a href="http://greenteapress.com/complexity2/html/thinkcomplexity2004.html"><img src="./Scale-free networks_files/back.png" alt="Previous"></a>
<a href="http://greenteapress.com/complexity2/html/index.html"><img src="./Scale-free networks_files/up.png" alt="Up"></a>
<a href="http://greenteapress.com/complexity2/html/thinkcomplexity2006.html"><img src="./Scale-free networks_files/next.png" alt="Next"></a>
<hr>
<table>

<tbody><tr>

<td valign="top" width="100" bgcolor="#b63e97" style="padding: 0px 10px;">
</td>

<td valign="top" width="500" style="padding: 10px;">

<p>This HTML version of <i>Think Complexity, 2nd Edition</i> is provided for convenience, but it is not the best format of the book.
In particular, some of the symbols are not rendered correctly.</p>

<p>You might prefer to read the <a href="http://greenteapress.com/complexity2/thinkcomplexity2.pdf">PDF version</a>.

</p><h1 id="sec34" class="chapter"><span style="font-size:medium">Chapter&nbsp;4&nbsp;&nbsp;Scale-free networks</span></h1>
<p><span style="font-size:medium">
</span><a id="scale-free"></a></p><p><span style="font-size:medium">In this chapter, we’ll work with data from an online social network, and use a
Watts-Strogatz graph to model it. The WS model has characteristics of
a small world network, like the data, but it has low
variability in the number of neighbors from node to node,
unlike the data.</span></p><p><span style="font-size:medium">This discrepancy is the motivation for a network model developed
by Barabási&nbsp;and Albert. The BA model captures the observed variability
in the number of neighbors, and it has one of the small world
properties, short path lengths, but it does not have the high
clustering of a small world network.</span></p><p><span style="font-size:medium">The chapter ends with a discussion of WS and BA graphs as explanatory
models for small world networks.</span></p><p><span style="font-size:medium">The code for this chapter is in <span style="font-family:monospace">chap04.ipynb</span> in the respository
for this book. More information about working with the code is
in Section&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2001.html#code"><span style="font-size:medium">??</span></a><span style="font-size:medium">.</span></p><span style="font-size:medium">
</span><h2 id="sec35" class="section"><span style="font-size:medium">4.1&nbsp;&nbsp;Social network data</span></h2>
<p><span style="font-size:medium">Watts-Strogatz graphs are intended to model networks in the natural
and social sciences. In their original paper, Watts and Strogatz
looked at the network of film actors (connected if they have appeared
in a movie together); the electrical power grid in the western United
States; and the network of neurons in the brain of the roundworm
<span style="font-style:italic">C. elegans</span>. They found that all of these networks had the
high connectivity and low path lengths characteristic of small world
graphs.</span></p><p><a id="hevea_default251"></a></p><p><span style="font-size:medium">In this section we’ll perform the same analysis with a different
dataset, a set of Facebook users and their friends. If you are not
familiar with Facebook, users who are connected to each other are
called “friends”, regardless of the nature of their relationship in
the real world.</span></p><p><a id="hevea_default252"></a><span style="font-size:medium">
</span><a id="hevea_default253"></a></p><p><span style="font-size:medium">I’ll use data from the Stanford Network Analysis Project (SNAP), which
shares large datasets from online social networks and other sources.
Specifically, I’ll use their Facebook data</span><sup><a id="text1" href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#note1"><span style="font-size:medium">1</span></a></sup><span style="font-size:medium">, which includes 4039 users and 88,234
friend relationships among them. This dataset is in the repository
for this book, but it is also available from the SNAP website at
</span><a href="http://thinkcomplex.com/snap"><span style="font-family:monospace;font-size:medium">http://thinkcomplex.com/snap</span></a><span style="font-size:medium">.</span></p><p><span style="font-size:medium">The data file contains one line per edge, with users identified by
integers from 0 to 4038. Here’s the code that reads the file:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">def read_graph(filename):
    G = nx.Graph()
    array = np.loadtxt(filename, dtype=<span style="color:blue">int</span>)
    G.add_edges_from(array)
    <span style="color:blue">return</span> G</span></td></tr>
</tbody></table><p><span style="font-size:medium">NumPy provides a function called <code>loadtext</code> that reads the
given file and returns the contents as a NumPy array. The
parameter <code>dtype</code> indicates that the “data type” of the array
is <span style="color:blue"><code>int</code></span>.</span></p><p><a id="hevea_default254"></a><span style="font-size:medium">
</span><a id="hevea_default255"></a><span style="font-size:medium">
</span><a id="hevea_default256"></a></p><p><span style="font-size:medium">Then we use <code>add_edges_from</code> to iterate the rows of the array
and make edges. Here are the results:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">&gt;&gt;&gt; fb = read_graph(<span style="color:#B20000">'facebook_combined.txt.gz'</span>)
&gt;&gt;&gt; n = len(fb)
&gt;&gt;&gt; m = len(fb.edges())
&gt;&gt;&gt; n, m
(4039, 88234)</span></td></tr>
</tbody></table><p><span style="font-size:medium">The node and edge counts are consistent with the documentation
of the dataset.</span></p><p><span style="font-size:medium">Now we can check whether this dataset has the characteristics of
a small world graph: high clustering and low path lengths.</span></p><p><span style="font-size:medium">In Section&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2004.html#clustering"><span style="font-size:medium">??</span></a><span style="font-size:medium"> we wrote a function to compute
the network average clustering coefficient. NetworkX provides
a function called <code>average_clustering</code>, which does the same
thing a little faster.</span></p><p><a id="hevea_default257"></a><span style="font-size:medium">
</span><a id="hevea_default258"></a></p><p><span style="font-size:medium">But for larger graphs, they are both too slow, taking time
proportional to <span style="font-style:italic">n k</span></span><sup><span style="font-size:medium">2</span></sup><span style="font-size:medium">, where <span style="font-style:italic">n</span> is the number of nodes and
<span style="font-style:italic">k</span> is the number of neighbors each node is connected to.</span></p><p><span style="font-size:medium">Fortunately, NetworkX provides a function that estimates the
clustering coefficient by random sampling. You can invoke it like
this:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">    from networkx.algorithms.approximation <span style="color:blue">import</span> average_clustering
    average_clustering(G, trials=1000)</span></td></tr>
</tbody></table><p><span style="font-size:medium">The following function does something similar for path lengths.</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">def sample_path_lengths(G, nodes=None, trials=1000):
    <span style="color:blue">if</span> nodes is None:
        nodes = list(G)
    <span style="color:blue">else</span>:
        nodes = list(nodes)

    pairs = np.random.choice(nodes, (trials, 2))
    lengths = [nx.shortest_path_length(G, *pair)
               <span style="color:blue">for</span> pair in pairs]
    <span style="color:blue">return</span> lengths</span></td></tr>
</tbody></table><p><span style="font-size:medium"><code>G</code> is a graph, <code>nodes</code> is the list of nodes to sample
from, and <code>trials</code> is the number of random paths to sample.
If <code>nodes</code> is <code>None</code>, we sample from the entire graph.</span></p><p><a id="hevea_default259"></a><span style="font-size:medium">
</span><a id="hevea_default260"></a><span style="font-size:medium">
</span><a id="hevea_default261"></a></p><p><span style="font-size:medium"><code>pairs</code> is a NumPy array of randomly chosen nodes with
one row for each trial and two columns.</span></p><p><a id="hevea_default262"></a></p><p><span style="font-size:medium">The list comprehension enumerates the rows in the array and
computes the shortest distance between each pair of nodes.
The result is a list of path lengths.</span></p><p><span style="font-size:medium"><code>estimate_path_length</code> generates a list of random path lengths and
returns their mean:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">def estimate_path_length(G, nodes=None, trials=1000):
    <span style="color:blue">return</span> np.mean(sample_path_lengths(G, nodes, trials))</span></td></tr>
</tbody></table><p><span style="font-size:medium">I’ll use <code>average_clustering</code> to compute <span style="font-style:italic">C</span>:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">C = average_clustering(fb)</span></td></tr>
</tbody></table><p><span style="font-size:medium">And <code>estimate_path_lengths</code> to compute <span style="font-style:italic">L</span>:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">L = estimate_path_lengths(fb)</span></td></tr>
</tbody></table><p><span style="font-size:medium">The clustering coefficient is about 0.61, which is high,
as we expect if this network has the small world property.</span></p><p><span style="font-size:medium">And the average path is 3.7, which is
quite short in a network of more than 4000 users. It’s a small
world after all.</span></p><p><span style="font-size:medium">Now let’s see if we can construct a WS graph that has the same
characteristics as this network.</span></p><span style="font-size:medium">
</span><h2 id="sec36" class="section"><span style="font-size:medium">4.2&nbsp;&nbsp;WS Model</span></h2>
<p><a id="hevea_default263"></a><span style="font-size:medium">
</span><a id="hevea_default264"></a></p><p><span style="font-size:medium">In the Facebook dataset, the average number of edges per node is about
22. Since each edge is connected to two nodes, the average degree
is twice the number of edges per node:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">&gt;&gt;&gt; k = <span style="color:blue">int</span>(round(2*m/n))
&gt;&gt;&gt; k
44</span></td></tr>
</tbody></table><p><span style="font-size:medium">We can make a WS graph with <code>n=4039</code> and <code>k=44</code>. When <code>p=0</code>, we
get a ring lattice.</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">lattice = nx.watts_strogatz_graph(n, k, 0)</span></td></tr>
</tbody></table><p><span style="font-size:medium">In this graph, clustering is high: <code>C</code> is 0.73, compared to 0.61
in the dataset. But <code>L</code> is 46, much higher
than in the dataset!</span></p><p><span style="font-size:medium">With <code>p=1</code> we get a random graph:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">random_graph = nx.watts_strogatz_graph(n, k, 1)</span></td></tr>
</tbody></table><p><span style="font-size:medium">In the random graph, <code>L</code> is 2.6, even shorter than
in the dataset (3.7), but <code>C</code> is only 0.011, so that’s no good.</span></p><p><span style="font-size:medium">By trial and error, we find that when <code>p=0.05</code> we get a WS graph with
high clustering and low path length:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">ws = nx.watts_strogatz_graph(n, k, 0.05, seed=15)</span></td></tr>
</tbody></table><p><span style="font-size:medium">In this graph <code>C</code> is 0.63, a bit higher than
in the dataset, and <code>L</code> is 3.2, a bit lower than in the dataset.
So this graph models the small world characteristics of the dataset
well.</span></p><p><span style="font-size:medium">So far, so good.</span></p><span style="font-size:medium">
</span><h2 id="sec37" class="section"><span style="font-size:medium">4.3&nbsp;&nbsp;Degree</span></h2>
<p><span style="font-size:medium">
</span><a id="degree"></a></p><blockquote class="figure"><div class="center"><hr style="width:80%;height:2"></div><span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="./Scale-free networks_files/thinkcomplexity2010.png"></span></div><span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 4.1: PMF of degree in the Facebook dataset and in the WS model.</span></td></tr>
</tbody></table></div><span style="font-size:medium">
</span><a id="chap04-1"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div></blockquote><p><span style="font-size:medium">If the WS graph is a good model for the Facebook network,
it should have the same average degree across nodes, and ideally the
same variance in degree.</span></p><p><a id="hevea_default265"></a></p><p><span style="font-size:medium">This function returns a list of degrees in a graph, one for each node:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">def degrees(G):
    <span style="color:blue">return</span> [G.degree(u) <span style="color:blue">for</span> u in G]</span></td></tr>
</tbody></table><p><span style="font-size:medium">The mean degree in model is 44, which is close to the mean degree in the dataset, 43.7.</span></p><p><span style="font-size:medium">However, the standard deviation of degree in the model is 1.5, which is not close to the standard deviation in the dataset, 52.4. Oops.</span></p><p><span style="font-size:medium">What’s the problem? To get a better view, we have to look at the
<span style="font-weight:bold">distribution</span> of degrees, not just the mean and standard deviation.</span></p><p><a id="hevea_default266"></a><span style="font-size:medium">
</span><a id="hevea_default267"></a><span style="font-size:medium">
</span><a id="hevea_default268"></a></p><p><span style="font-size:medium">I’ll represent the distribution of degrees with a <code>Pmf</code> object,
which is defined in the <code>thinkstats2</code> module.
<code>Pmf</code> stands for “probability mass function”;
if you are not familiar with this concept,
you might want to read Chapter 3 of <span style="font-style:italic">Think Stats, 2nd edition</span>
at </span><a href="http://thinkcomplex.com/ts2"><span style="font-family:monospace;font-size:medium">http://thinkcomplex.com/ts2</span></a><span style="font-size:medium">.</span></p><p><span style="font-size:medium">Briefly, a <code>Pmf</code> maps from values to their probabilities.
A <code>Pmf</code> of degrees is a mapping from each possible degree, <span style="font-style:italic">d</span>, to the
fraction of nodes with degree <span style="font-style:italic">d</span>.</span></p><p><span style="font-size:medium">As an example, I’ll construct a graph with nodes 1, 2, and 3 connected
to a central node, 0:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">G = nx.Graph()
G.add_edge(1, 0)
G.add_edge(2, 0)
G.add_edge(3, 0)
nx.draw(G)</span></td></tr>
</tbody></table><p><span style="font-size:medium">Here’s the list of degrees in this graph:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">&gt;&gt;&gt; degrees(G)
[3, 1, 1, 1]</span></td></tr>
</tbody></table><p><span style="font-size:medium">Node 0 has degree 3, the others have degree 1. Now I can make
a <code>Pmf</code> that represents this degree distribution:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">&gt;&gt;&gt; from thinkstats2 <span style="color:blue">import</span> Pmf
&gt;&gt;&gt; Pmf(degrees(G))
Pmf({1: 0.75, 3: 0.25})</span></td></tr>
</tbody></table><p><span style="font-size:medium">The result is a <code>Pmf</code> object that maps from each degree to a
fraction or probability. In this example, 75% of the nodes have
degree 1 and 25% have degree 3.</span></p><p><span style="font-size:medium">Now we can make a <code>Pmf</code> that contains node degrees from the
dataset, and compute the mean and standard deviation:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">&gt;&gt;&gt; from thinkstats2 <span style="color:blue">import</span> Pmf
&gt;&gt;&gt; pmf_fb = Pmf(degrees(fb))
&gt;&gt;&gt; pmf_fb.Mean(), pmf_fb.Std()
(43.691, 52.414)</span></td></tr>
</tbody></table><p><span style="font-size:medium">And the same for the WS model:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">&gt;&gt;&gt; pmf_ws = Pmf(degrees(ws))
&gt;&gt;&gt; pmf_ws.mean(), pmf_ws.std()
(44.000, 1.465)</span></td></tr>
</tbody></table><p><span style="font-size:medium">We can use the <code>thinkplot</code> module to plot the results:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">thinkplot.Pdf(pmf_fb, label=<span style="color:#B20000">'Facebook'</span>)
thinkplot.Pdf(pmf_ws, label=<span style="color:#B20000">'WS graph'</span>)</span></td></tr>
</tbody></table><p><span style="font-size:medium">Figure&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#chap04-1"><span style="font-size:medium">??</span></a><span style="font-size:medium"> shows the two distributions. They are
very different.</span></p><p><a id="hevea_default269"></a></p><p><span style="font-size:medium">In the WS model, most users have about 44 friends; the minimum is 38
and the maximum is 50. That’s not much variation.
In the dataset, there are many users with only 1 or 2 friends,
but one has more than 1000!</span></p><p><a id="hevea_default270"></a></p><p><span style="font-size:medium">Distributions like this, with many small values and a few very large
values, are called <span style="font-weight:bold">heavy-tailed</span>.</span></p><span style="font-size:medium">
</span><h2 id="sec38" class="section"><span style="font-size:medium">4.4&nbsp;&nbsp;Heavy-tailed distributions</span></h2>
<p><span style="font-size:medium">
</span><a id="heavytail"></a></p><blockquote class="figure"><div class="center"><hr style="width:80%;height:2"></div><span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="./Scale-free networks_files/thinkcomplexity2011.png"></span></div><span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 4.2: PMF of degree in the Facebook dataset and in the WS model,
on a log-log scale.</span></td></tr>
</tbody></table></div><span style="font-size:medium">
</span><a id="chap04-2"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div></blockquote><p><span style="font-size:medium">Heavy-tailed distributions are a
common feature in many areas of complexity science and they will be a
recurring theme of this book.</span></p><p><span style="font-size:medium">We can get a clearer picture of a heavy-tailed distribution by
plotting it on a log-log axis, as shown in Figure&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#chap04-2"><span style="font-size:medium">??</span></a><span style="font-size:medium">.
This transformation emphasizes the tail of the distribution; that
is, the probabilities of large values.</span></p><p><a id="hevea_default271"></a><span style="font-size:medium">
</span><a id="hevea_default272"></a><span style="font-size:medium">
</span><a id="hevea_default273"></a></p><p><span style="font-size:medium">Under this transformation, the data fall approximately on a
straight line, which suggests that there is a <span style="font-weight:bold">power law</span>
relationship between the largest values in the distribution and their
probabilities. Mathematically, a distribution obeys a power law if
</span></p><table class="display dcenter"><tbody><tr style="vertical-align:middle"><td class="dcell"><span style="font-size:medium"><span style="font-style:italic">PMF</span>(<span style="font-style:italic">k</span>)&nbsp;&#8764;&nbsp;<span style="font-style:italic">k</span></span><sup><span style="font-size:medium">&#8722;&#945;</span></sup><span style="font-size:medium">&nbsp;</span></td></tr>
</tbody></table><p><span style="font-size:medium">
where <span style="font-style:italic">PMF</span>(<span style="font-style:italic">k</span>) is the fraction of nodes with degree <span style="font-style:italic">k</span>, &#945;
is a parameter, and the symbol &#8764; indicates that the PMF is
asymptotic to <span style="font-style:italic">k</span></span><sup><span style="font-size:medium">&#8722;&#945;</span></sup><span style="font-size:medium"> as <span style="font-style:italic">k</span> increases.</span></p><p><span style="font-size:medium">If we take the log of both sides, we get
</span></p><table class="display dcenter"><tbody><tr style="vertical-align:middle"><td class="dcell"><span style="font-size:medium">log<span style="font-style:italic">PMF</span>(<span style="font-style:italic">k</span>)&nbsp;&#8764;&nbsp;&#8722;&#945;&nbsp;log<span style="font-style:italic">k</span>&nbsp;</span></td></tr>
</tbody></table><p><span style="font-size:medium">
So if a distribution follows a power law and we plot <span style="font-style:italic">PMF</span>(<span style="font-style:italic">k</span>) versus
<span style="font-style:italic">k</span> on a log-log scale, we expect a straight line with slope
&#8722;&#945;, at least for large values of <span style="font-style:italic">k</span>.</span></p><p><span style="font-size:medium">All power law distributions are heavy-tailed, but there are other
heavy-tailed distributions that don’t follow a power law. We will
see more examples soon.</span></p><p><span style="font-size:medium">But first, we have a problem: the WS model has the high clustering
and low path length we see in the data, but the degree distribution
doesn’t resemble the data at all. This discrepancy is the motivation
for our next topic, the Barabási-Albert model.</span></p><span style="font-size:medium">
</span><h2 id="sec39" class="section"><span style="font-size:medium">4.5&nbsp;&nbsp;Barabási-Albert model</span></h2>
<p><span style="font-size:medium">
</span><a id="scale.free"></a></p><p><span style="font-size:medium">In 1999 Barabási&nbsp;and Albert published a paper,
“Emergence of Scaling in Random Networks”, that characterizes the
structure of several real-world networks,
including graphs that represent the interconnectivity of movie actors,
web pages, and elements in the electrical power grid
in the western United States. You can download the paper from
</span><a href="http://thinkcomplex.com/barabasi"><span style="font-family:monospace;font-size:medium">http://thinkcomplex.com/barabasi</span></a><span style="font-size:medium">.</span></p><p><a id="hevea_default274"></a><span style="font-size:medium">
</span><a id="hevea_default275"></a><span style="font-size:medium">
</span><a id="hevea_default276"></a><span style="font-size:medium">
</span><a id="hevea_default277"></a></p><p><span style="font-size:medium">They measure the degree of each node and compute <span style="font-style:italic">PMF</span>(<span style="font-style:italic">k</span>), the
probability that a vertex has degree <span style="font-style:italic">k</span>. Then they plot <span style="font-style:italic">PMF</span>(<span style="font-style:italic">k</span>)
versus <span style="font-style:italic">k</span> on a log-log scale. The plots fit a
straight line, at least for large values of <span style="font-style:italic">k</span>,
so Barabási&nbsp;and Albert conclude that these
distributions are heavy-tailed.</span></p><p><span style="font-size:medium">They also propose a model that generates graphs with the same
property. The essential features of the model, which distinguish it
from the WS model, are:</span></p><p><a id="hevea_default278"></a><span style="font-size:medium">
</span><a id="hevea_default279"></a></p><dl class="description"><dt class="dt-description"><span style="font-weight:bold;font-size:medium">Growth:</span></dt><dd class="dd-description"><span style="font-size:medium"> Instead of starting with a fixed number of vertices,
the BA model starts with a small graph and adds vertices one at a time.</span></dd><dt class="dt-description"><span style="font-weight:bold;font-size:medium">Preferential attachment:</span></dt><dd class="dd-description"><span style="font-size:medium"> When a new edge is created, it is
more likely to connect to a vertex that already has a large number
of edges. This “rich get richer” effect is characteristic of
the growth patterns of some real-world networks.</span><p><a id="hevea_default280"></a><span style="font-size:medium">
</span><a id="hevea_default281"></a></p></dd></dl><p><span style="font-size:medium">Finally, they show that graphs generated by the Barabási-Albert (BA)
model have a degree distribution that obeys a power law.</span></p><p><a id="hevea_default282"></a></p><p><span style="font-size:medium">Graphs with this property are sometimes called <span style="font-weight:bold">scale-free networks</span>,
for reasons I won’t explain; if you are curious, you can read more
at </span><a href="http://thinkcomplex.com/scale"><span style="font-family:monospace;font-size:medium">http://thinkcomplex.com/scale</span></a><span style="font-size:medium">.</span></p><p><a id="hevea_default283"></a><span style="font-size:medium">
</span><a id="hevea_default284"></a></p><p><span style="font-size:medium">NetworkX provides a function that generates BA graphs. We will use
it first; then I’ll show you how it works.</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">ba = nx.barabasi_albert_graph(n=4039, k=22)</span></td></tr>
</tbody></table><p><span style="font-size:medium">The parameters are <code>n</code>, the number of nodes to generate, and
<code>k</code>, the number of edges each node starts with when it is added to
the graph. I chose <code>k=22</code> because that is the average number
of edges per node in the dataset.</span></p><blockquote class="figure"><div class="center"><hr style="width:80%;height:2"></div><span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="./Scale-free networks_files/thinkcomplexity2012.png"></span></div><span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 4.3: PMF of degree in the Facebook dataset and in the BA model,
on a log-log scale.</span></td></tr>
</tbody></table></div><span style="font-size:medium">
</span><a id="chap04-3"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div></blockquote><p><span style="font-size:medium">The resulting graph has 4039 nodes and 21.9 edges per node.
Since every edge is connected to two nodes, the average degree
is 43.8, very close to the average degree in the dataset,
43.7.</span></p><p><span style="font-size:medium">And the standard deviation of degree is 40.9, which is a bit
less than in the dataset, 52.4, but it is much better
than what we got from the WS graph, 1.5.</span></p><p><span style="font-size:medium">Figure&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#chap04-3"><span style="font-size:medium">??</span></a><span style="font-size:medium"> shows the degree distributions for the
Facebook dataset and the BA model on a log-log scale. The model
is not perfect; in particular, it deviates from the data when
<code>k</code> is less than 10. But the tail looks like a straight line,
which suggests that this process generates degree distributions
that follow a power law.</span></p><p><a id="hevea_default285"></a></p><p><span style="font-size:medium">So the BA model is better than the WS model at reproducing the degree
distribution. But does it have the small world property?</span></p><p><a id="hevea_default286"></a></p><p><span style="font-size:medium">In this example, the average path length, <span style="font-style:italic">L</span>, is 2.5, which
is even more “small world” than the actual network, which has
<span style="font-style:italic">L</span>=3.69. So that’s good, although maybe too good.</span></p><p><a id="hevea_default287"></a></p><p><span style="font-size:medium">On the other hand, the clustering coefficient, <span style="font-style:italic">C</span>, is 0.037,
not even close to the value in the dataset, 0.61.
So that’s a problem.</span></p><p><span style="font-size:medium">Table&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#table04-1"><span style="font-size:medium">??</span></a><span style="font-size:medium"> summarizes these results. The WS model captures
the small world characteristics, but not the degree distribution. The
BA model captures the degree distribution, at least approximately,
and the average path length, but not the clustering coefficient.</span></p><p><span style="font-size:medium">In the exercises at the end of this chapter, you can explore other
models intended to capture all of these characteristics.</span></p><blockquote class="table"><div class="center"><div class="center"><hr style="width:80%;height:2"></div><span style="font-size:medium">
</span><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td class="hbar" colspan="4"></td></tr>
<tr><td style="text-align:left;white-space:nowrap"><span style="font-size:medium">&nbsp;</span></td><td style="text-align:right;white-space:nowrap"><span style="font-weight:bold;font-size:medium">Facebook</span></td><td style="text-align:right;white-space:nowrap"><span style="font-weight:bold;font-size:medium">WS model</span></td><td style="text-align:right;white-space:nowrap"><span style="font-weight:bold;font-size:medium">BA model </span></td></tr>
<tr><td class="hbar" colspan="4"></td></tr>
<tr><td style="text-align:left;white-space:nowrap"><span style="font-size:medium">C</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">0.61</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">0.63</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">0.037 </span></td></tr>
<tr><td style="text-align:left;white-space:nowrap"><span style="font-size:medium">L</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">3.69</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">3.23</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">2.51 </span></td></tr>
<tr><td style="text-align:left;white-space:nowrap"><span style="font-size:medium">Mean degree</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">43.7</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">44</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">43.7 </span></td></tr>
<tr><td style="text-align:left;white-space:nowrap"><span style="font-size:medium">Std degree</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">52.4</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">1.5</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">40.1 </span></td></tr>
<tr><td style="text-align:left;white-space:nowrap"><span style="font-size:medium">Power law?</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">maybe</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">no</span></td><td style="text-align:right;white-space:nowrap"><span style="font-size:medium">yes </span></td></tr>
<tr><td class="hbar" colspan="4"></td></tr>
</tbody></table><span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Table 4.1: Characteristics of the Facebook dataset compared to two models.</span></td></tr>
</tbody></table></div><span style="font-size:medium">
</span><a id="table04-1"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div></div></blockquote><span style="font-size:medium">
</span><h2 id="sec40" class="section"><span style="font-size:medium">4.6&nbsp;&nbsp;Generating BA graphs</span></h2>
<p><span style="font-size:medium">In the previous sections we used a NetworkX function to generate BA
graphs; now let’s see how it works. Here is a version
of <code>barabasi_albert_graph</code>, with some changes I made to
make it easier to read:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">def barabasi_albert_graph(n, k):

    G = nx.empty_graph(k)
    targets = list(range(k))
    repeated_nodes = []

    <span style="color:blue">for</span> source in range(k, n):
        G.add_edges_from(zip([source]*k, targets))

        repeated_nodes.extend(targets)
        repeated_nodes.extend([source] * k)

        targets = _random_subset(repeated_nodes, k)

    <span style="color:blue">return</span> G</span></td></tr>
</tbody></table><p><span style="font-size:medium">The parameters are <code>n</code>, the number of nodes we want, and <code>k</code>, the
number of edges each new node gets (which will turn out to be
the average number of edges per node).</span></p><p><a id="hevea_default288"></a><span style="font-size:medium">
</span><a id="hevea_default289"></a></p><p><span style="font-size:medium">We start with a graph that has <code>k</code> nodes and no edges. Then we
initialize two variables:</span></p><dl class="description"><dt class="dt-description"><span style="font-weight:bold;font-size:medium"><code>targets</code>:</span></dt><dd class="dd-description"><span style="font-size:medium"> The list of <code>k</code> nodes that will be connected
to the next node. Initially <code>targets</code> contains the original
<code>k</code> nodes; later it will contain a random subset of nodes.</span></dd><dt class="dt-description"><span style="font-weight:bold;font-size:medium"><code>repeated_nodes</code>:</span></dt><dd class="dd-description"><span style="font-size:medium"> A list of existing nodes where each
node appears once for every edge it is connected to. When we
select from <code>repeated_nodes</code>, the probability of selecting any
node is proportional to the number of edges it has.</span></dd></dl><p><span style="font-size:medium">Each time through the loop, we add edges from the source to
each node in <code>targets</code>. Then we update <code>repeated_nodes</code> by
adding each target once and the new node <code>k</code> times.</span></p><p><span style="font-size:medium">Finally, we choose a subset of the nodes to be targets for the
next iteration. Here’s the definition of <code>_random_subset</code>:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">def _random_subset(repeated_nodes, k):
    targets = set()
    <span style="color:blue">while</span> len(targets) &lt; k:
        x = random.choice(repeated_nodes)
        targets.add(x)
    <span style="color:blue">return</span> targets</span></td></tr>
</tbody></table><p><span style="font-size:medium">Each time through the loop, <code>_random_subset</code> chooses from
<code>repeated_nodes</code> and adds the chosen node to <code>targets</code>. Because
<code>targets</code> is a set, it automatically discards duplicates, so
the loop only exits when we have selected <code>k</code> different nodes.</span></p><span style="font-size:medium">
</span><h2 id="sec41" class="section"><span style="font-size:medium">4.7&nbsp;&nbsp;Cumulative distributions</span></h2>
<p><span style="font-size:medium">
</span><a id="cdf"></a></p><blockquote class="figure"><div class="center"><hr style="width:80%;height:2"></div><span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="./Scale-free networks_files/thinkcomplexity2013.png"></span></div><span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 4.4: CDF of degree in the Facebook dataset along with the WS model (left) and the BA model (right), on a log-x scale.</span></td></tr>
</tbody></table></div><span style="font-size:medium">
</span><a id="chap04-4"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div></blockquote><p><span style="font-size:medium">Figure&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#chap04-3"><span style="font-size:medium">??</span></a><span style="font-size:medium"> represents the degree distribution by plotting
the probability mass function (PMF) on a log-log scale. That’s how
Barabási&nbsp;and Albert present their results and it is the representation
used most often in articles about power law distributions. But it
is not the best way to look at data like this.</span></p><p><span style="font-size:medium">A better alternative is a <span style="font-weight:bold">cumulative distribution function</span>
(CDF), which maps from a value, <span style="font-style:italic">x</span>, to the fraction of values less
than or equal to <span style="font-style:italic">x</span>.</span></p><p><a id="hevea_default290"></a><span style="font-size:medium">
</span><a id="hevea_default291"></a></p><p><span style="font-size:medium">Given a <code>Pmf</code>, the simplest way to compute a cumulative probability
is to add up the probabilities for values up to and including <span style="font-style:italic">x</span>:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">def cumulative_prob(pmf, x):
    ps = [pmf[value] <span style="color:blue">for</span> value in pmf <span style="color:blue">if</span> value&lt;=x]
    <span style="color:blue">return</span> np.sum(ps)</span></td></tr>
</tbody></table><p><span style="font-size:medium">For example, given the degree distribution in the dataset,
<code>pmf_fb</code>, we can compute the fraction of users with 25 or fewer
friends:</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">&gt;&gt;&gt; cumulative_prob(pmf_fb, 25)
0.506</span></td></tr>
</tbody></table><p><span style="font-size:medium">The result is close to 0.5, which means that the median number
of friends is about 25.</span></p><p><span style="font-size:medium">CDFs are better for visualization because they are less noisy than
PMFs. Once you get used to interpreting CDFs, they provide
a clearer picture of the shape of a
distribution than PMFs.</span></p><p><span style="font-size:medium">The <code>thinkstats</code> module provides a class called <code>Cdf</code> that
represents a cumulative distribution function. We can use it
to compute the CDF of degree in the dataset.</span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">from thinkstats2 <span style="color:blue">import</span> Cdf
cdf_fb = Cdf(degrees(fb), label=<span style="color:#B20000">'Facebook'</span>)</span></td></tr>
</tbody></table><p><span style="font-size:medium">And <code>thinkplot</code> provides a function called <code>Cdf</code> that plots
cumulative distribution functions.</span></p><p><a id="hevea_default292"></a></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium">thinkplot.Cdf(cdf_fb)</span></td></tr>
</tbody></table><p><span style="font-size:medium">Figure&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#chap04-4"><span style="font-size:medium">??</span></a><span style="font-size:medium"> shows the degree CDF for the Facebook dataset
along with the WS model (left) and the BA model (right). The x-axis
is on a log scale.</span></p><blockquote class="figure"><div class="center"><hr style="width:80%;height:2"></div><span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="./Scale-free networks_files/thinkcomplexity2014.png"></span></div><span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 4.5: Complementary CDF of degree in the Facebook dataset along with the WS model (left) and the BA model (right), on a log-log scale.</span></td></tr>
</tbody></table></div><span style="font-size:medium">
</span><a id="chap04-5"></a><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div></blockquote><p><span style="font-size:medium">Clearly the CDF for the WS model is very different from the CDF
from the data. The BA model is better, but still not very good,
especially for small values.</span></p><p><a id="hevea_default293"></a><span style="font-size:medium">
</span><a id="hevea_default294"></a></p><p><span style="font-size:medium">In the tail of the distribution (values greater than 100) it looks
like the BA model matches the dataset well enough, but it is
hard to see. We can get a clearer view with one other view of the
data: plotting the complementary CDF on a log-log scale.</span></p><p><span style="font-size:medium">The <span style="font-weight:bold">complementary CDF</span> (CCDF) is defined
</span></p><table class="display dcenter"><tbody><tr style="vertical-align:middle"><td class="dcell"><span style="font-size:medium"><span style="font-style:italic">CCDF</span>(<span style="font-style:italic">x</span>)&nbsp;&#8801;&nbsp;1&nbsp;&#8722;&nbsp;<span style="font-style:italic">CDF</span>(<span style="font-style:italic">x</span>)&nbsp;</span></td></tr>
</tbody></table><p><span style="font-size:medium">
This definition is useful because if the PMF follows a power law, the CCDF
also follows a power law:
</span></p><table class="display dcenter"><tbody><tr style="vertical-align:middle"><td class="dcell"><span style="font-size:medium"><span style="font-style:italic">CCDF</span>(<span style="font-style:italic">x</span>)&nbsp;&#8764;&nbsp;</span></td><td class="dcell"><span style="font-size:medium">&#9115;<br>
&#9116;<br>
&#9116;<br>
&#9117;</span></td><td class="dcell"><table class="display"><tbody><tr><td class="dcell" style="text-align:center"><span style="font-style:italic;font-size:medium">x</span></td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-style:italic;font-size:medium">x</span><sub><span style="font-style:italic;font-size:medium">m</span></sub></td></tr>
</tbody></table></td><td class="dcell"><span style="font-size:medium">&nbsp;</span></td><td class="dcell"><span style="font-size:medium">&#9118;<br>
&#9119;<br>
&#9119;<br>
&#9120;</span></td><td class="dcell"><table class="display"><tbody><tr><td class="dcell" style="text-align:left"><span style="font-size:medium">&#8722;&#945;</span></td></tr>
<tr><td class="dcell" style="text-align:left"><span style="font-size:medium"><br>
<br>
<br>
</span></td></tr>
<tr><td class="dcell" style="text-align:left"><span style="font-size:medium">&nbsp;</span></td></tr>
</tbody></table></td><td class="dcell"><span style="font-size:medium">&nbsp;</span></td></tr>
</tbody></table><p><span style="font-size:medium">
where <span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">m</span></sub><span style="font-size:medium"> is the minimum possible value and &#945; is a parameter
that determines the shape of the distribution.</span></p><p><span style="font-size:medium">Taking the log of both sides yields:
</span></p><table class="display dcenter"><tbody><tr style="vertical-align:middle"><td class="dcell"><span style="font-size:medium">log<span style="font-style:italic">CCDF</span>(<span style="font-style:italic">x</span>)&nbsp;&#8764;&nbsp;&#8722;&#945;&nbsp;(log<span style="font-style:italic">x</span>&nbsp;&#8722;&nbsp;log<span style="font-style:italic">x</span></span><sub><span style="font-style:italic;font-size:medium">m</span></sub><span style="font-size:medium">)&nbsp;</span></td></tr>
</tbody></table><p><span style="font-size:medium">
So if the distribution obeys a power law, we expect the CCDF on
a log-log scale to be a straight line with slope &#8722;&#945;.</span></p><p><a id="hevea_default295"></a></p><p><span style="font-size:medium">Figure&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#chap04-5"><span style="font-size:medium">??</span></a><span style="font-size:medium"> shows the CCDF of degree for the Facebook data,
along with the WS model (left) and the BA model (right), on a log-log
scale.</span></p><p><span style="font-size:medium">With this way of looking at the data, we can see that the BA model
matches the tail of the distribution (values above 20) reasonably well.
The WS model does not.</span></p><span style="font-size:medium">
</span><h2 id="sec42" class="section"><span style="font-size:medium">4.8&nbsp;&nbsp;Explanatory models</span></h2>
<p><span style="font-size:medium">
</span><a id="model1"></a></p><blockquote class="figure"><div class="center"><hr style="width:80%;height:2"></div><span style="font-size:medium">
</span><div class="center"><span style="font-size:medium"><img src="./Scale-free networks_files/thinkcomplexity2015.png"></span></div><span style="font-size:medium">
</span><div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tbody><tr><td style="vertical-align:top;text-align:left;"><span style="font-size:medium">Figure 4.6: The logical structure of an explanatory model.</span><a id="fig.model"></a></td></tr>
</tbody></table></div><span style="font-size:medium">
</span><div class="center"><hr style="width:80%;height:2"></div></blockquote><p><span style="font-size:medium">We started the discussion of networks with Milgram’s Small World
Experiment, which shows that path lengths in social
networks are surprisingly small; hence, “six degrees of separation”.</span></p><p><a id="hevea_default296"></a><span style="font-size:medium">
</span><a id="hevea_default297"></a><span style="font-size:medium">
</span><a id="hevea_default298"></a><span style="font-size:medium">
</span><a id="hevea_default299"></a><span style="font-size:medium">
</span><a id="hevea_default300"></a><span style="font-size:medium">
</span><a id="hevea_default301"></a></p><p><span style="font-size:medium">When we see something surprising, it is natural to ask “Why?” but
sometimes it’s not clear what kind of answer we are looking for. One
kind of answer is an <span style="font-weight:bold">explanatory model</span> (see
Figure&nbsp;</span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#fig.model"><span style="font-size:medium">??</span></a><span style="font-size:medium">). The logical structure of an explanatory
model is:</span></p><ol class="enumerate" type="1"><li class="li-enumerate"><span style="font-size:medium">In a system, S, we see something observable, O, that warrants
explanation.</span></li><li class="li-enumerate"><span style="font-size:medium">We construct a model, M, that is analogous to the system; that
is, there is a correspondence between the elements of the model and
the elements of the system.</span></li><li class="li-enumerate"><span style="font-size:medium">By simulation or mathematical derivation, we show that the model
exhibits a behavior, B, that is analogous to O.</span></li><li class="li-enumerate"><span style="font-size:medium">We conclude that S exhibits O <em>because</em> S is similar to M, M
exhibits B, and B is similar to O.</span></li></ol><p><span style="font-size:medium">At its core, this is an argument by analogy, which says that if two
things are similar in some ways, they are likely to be similar in
other ways.</span></p><p><a id="hevea_default302"></a><span style="font-size:medium">
</span><a id="hevea_default303"></a></p><p><span style="font-size:medium">Argument by analogy can be useful, and explanatory models can be
satisfying, but they do not constitute a proof in the mathematical
sense of the word.</span></p><p><a id="hevea_default304"></a><span style="font-size:medium">
</span><a id="hevea_default305"></a></p><p><span style="font-size:medium">Remember that all models leave out, or “abstract away”,
details that we think are unimportant. For any system there
are many possible models that include or ignore different features.
And there might be models that exhibit different behaviors that are similar to O in different ways.
In that case, which model explains O?</span></p><p><a id="hevea_default306"></a></p><p><span style="font-size:medium">The small world phenomenon is an example: the Watts-Strogatz (WS)
model and the Barabási-Albert (BA) model both exhibit elements of
small world behavior, but they offer different explanations:</span></p><ul class="itemize"><li class="li-itemize"><span style="font-size:medium">The WS model suggests that social networks are “small” because
they include both strongly-connected clusters and “weak ties” that
connect clusters (see </span><a href="http://thinkcomplex.com/weak"><span style="font-family:monospace;font-size:medium">http://thinkcomplex.com/weak</span></a><span style="font-size:medium">).</span><p><a id="hevea_default307"></a></p></li><li class="li-itemize"><span style="font-size:medium">The BA model suggests that social networks are small because
they include nodes with high degree that act as hubs, and that
hubs grow, over time, due to preferential attachment.</span><p><a id="hevea_default308"></a></p></li></ul><p><span style="font-size:medium">As is often the case in young areas of science, the problem is
not that we have no explanations, but too many.</span></p><span style="font-size:medium">
</span><h2 id="sec43" class="section"><span style="font-size:medium">4.9&nbsp;&nbsp;Exercises</span></h2>
<div class="theorem"><span style="font-size:medium"><span style="font-weight:bold">Exercise&nbsp;1</span>&nbsp;&nbsp;</span><p><span style="font-size:medium"><em>In Section&nbsp;</em></span><a href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#model1"><span style="font-size:medium"><em>??</em></span></a><span style="font-size:medium"><em> we discussed two explanations for the
small world phenomenon, “weak ties” and “hubs”.
Are these explanations compatible; that is, can they both be right?
Which do you find more satisfying as an explanation, and why?</em></span></p><p><a id="hevea_default309"></a><span style="font-size:medium">
</span><a id="hevea_default310"></a></p><p><span style="font-size:medium"><em>Is there data you could collect, or experiments you could perform,
that would provide evidence in favor of one model over the other?</em></span></p><p><span style="font-size:medium"><em>Choosing among competing models is the topic of Thomas Kuhn’s
essay, “Objectivity, Value Judgment, and Theory Choice”, which
you can read at </em></span><a href="http://thinkcomplex.com/kuhn"><span style="font-family:monospace;font-size:medium"><em>http://thinkcomplex.com/kuhn</em></span></a><span style="font-size:medium"><em>.</em></span></p><p><a id="hevea_default311"></a><span style="font-size:medium">
</span><a id="hevea_default312"></a><span style="font-size:medium">
</span><a id="hevea_default313"></a></p><p><span style="font-size:medium"><em>What criteria does Kuhn propose for choosing among competing models?
Do these criteria influence your opinion about the WS and BA models?
Are there other criteria you think should be considered?</em></span></p></div><div class="theorem"><span style="font-size:medium"><span style="font-weight:bold">Exercise&nbsp;2</span>&nbsp;&nbsp;</span><p><span style="font-size:medium"><em>NetworkX provides a function called <code>powerlaw_cluster_graph</code> that
implements the "Holme and Kim algorithm for growing graphs with
powerlaw degree distribution and approximate average clustering".
Read the documentation of this function (</em></span><a href="http://thinkcomplex.com/hk"><span style="font-family:monospace;font-size:medium"><em>http://thinkcomplex.com/hk</em></span></a><span style="font-size:medium"><em>) and see if you can use it to
generate a graph that has the same number of nodes as the Facebook
dataset, the same average degree, and the same clustering coefficient.
How does the degree distribution in the model compare to the actual
distribution?</em></span></p><p><a id="hevea_default314"></a><span style="font-size:medium">
</span><a id="hevea_default315"></a></p></div><div class="theorem"><span style="font-size:medium"><span style="font-weight:bold">Exercise&nbsp;3</span>&nbsp;&nbsp;</span><p><span style="font-size:medium"><em>Data files from the Barabási&nbsp;and Albert paper are available from
</em></span><a href="http://thinkcomplex.com/netdata"><span style="font-family:monospace;font-size:medium"><em>http://thinkcomplex.com/netdata</em></span></a><span style="font-size:medium"><em>. Their actor collaboration data is included in the repository for this book in a
file named <code>actor.dat.gz</code>. The following function reads the file and
builds the graph.</em></span></p><table class="lstframe" style="padding:1ex;background-color:#FAFAFA;"><tbody><tr><td class="lstlisting"><span style="font-size:medium"><em><span style="color:blue">import</span> gzip

def read_actor_network(filename, n=None):
    G = nx.Graph()
    with gzip.open(filename) as f:
        <span style="color:blue">for</span> i, line in enumerate(f):
            nodes = [<span style="color:blue">int</span>(x) <span style="color:blue">for</span> x in line.split()]
            G.add_edges_from(thinkcomplexity.all_pairs(nodes))
            <span style="color:blue">if</span> n and i &gt;= n:
                <span style="color:blue">break
    return</span> G</em></span></td></tr>
</tbody></table><p><span style="font-size:medium"><em>Compute the number of actors in the graph and the average degree.
Plot the PMF of degree on a log-log scale. Also plot the CDF of
degree on a log-x scale, to see the general shape of the distribution,
and on a log-log scale, to see whether the tail follows a power law.</em></span></p><p><span style="font-size:medium"><em>Note: The actor network is not connected, so you might want to use
<code>nx.connected_component_subgraphs</code> to find connected subsets of the
nodes.</em></span></p></div><span style="font-size:medium">
</span><hr class="footnoterule"><dl class="thefootnotes"><dt class="dt-thefootnotes"><span style="font-size:medium">
</span><a id="note1" href="http://greenteapress.com/complexity2/html/thinkcomplexity2005.html#text1"><span style="font-size:medium">1</span></a></dt><dd class="dd-thefootnotes"><span style="font-size:medium"><div class="footnotetext">J. McAuley and
J. Leskovec. Learning to Discover Social Circles in Ego
Networks. NIPS, 2012.</div></span></dd></dl>
</td>

<td valign="top" width="130" style="padding: 0px 10px;">

<a href="https://amzn.to/2IbQpnp">Buy this book at Amazon.com</a>

<h4>Contribute</h4>
If you would like to make a contribution to support my books,
you can use the button below and pay with PayPal.  Thank you!

<form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_top">
<input type="hidden" name="cmd" value="_s-xclick">
<input type="hidden" name="hosted_button_id" value="RAAYAZ7Y48S2A">
<table>
<tbody><tr><td><input type="hidden" name="on0" value="Pay what you want!">Pay what you want:</td></tr><tr><td><select name="os0">
	<option value="Small">Small $1.00 USD</option>
	<option value="Medium">Medium $5.00 USD</option>
	<option value="Large">Large $10.00 USD</option>
	<option value="X-Large">X-Large $20.00 USD</option>
	<option value="XX-Large">XX-Large $50.00 USD</option>
</select> </td></tr>
</tbody></table>
<input type="hidden" name="currency_code" value="USD">
<input type="image" src="./Scale-free networks_files/btn_paynow_LG.gif" border="0" name="submit" alt="PayPal - The safer, easier way to pay online!">
<img alt="" border="0" src="./Scale-free networks_files/pixel.gif" width="1" height="1">
</form>


<p>
</p><h4>Are you using one of our books in a class?</h4>  We'd like to know
about it.  Please consider filling out <a href="http://spreadsheets.google.com/viewform?formkey=dC0tNUZkMjBEdXVoRGljNm9FRmlTMHc6MA" onclick="javascript: pageTracker._trackPageview(&#39;/outbound/survey&#39;);">this short survey</a>.

<p>
<br>

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491938455/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491938455&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=2JJH4SWCAVVYSQHO">Think DSP</a>
<img src="./Scale-free networks_files/ir" width="1" height="1" border="0" alt="">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491938455/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491938455&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=CTV7PDT7E5EGGJUM">
<img border="0" src="./Scale-free networks_files/q"></a>
<img src="./Scale-free networks_files/ir" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491929561/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491929561&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=ZY6MAYM33ZTNSCNZ">Think Java</a>
<img src="./Scale-free networks_files/ir(1)" width="1" height="1" border="0" alt="">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491929561/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491929561&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=PT77ANWARUNNU3UK">
<img border="0" src="./Scale-free networks_files/q(1)"></a>
<img src="./Scale-free networks_files/ir(1)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1449370780/ref=as_li_qf_sp_asin_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1449370780&amp;linkCode=as2&amp;tag=greenteapre01-20">Think Bayes</a>
<img src="./Scale-free networks_files/ir(2)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1449370780/ref=as_li_qf_sp_asin_il?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1449370780&amp;linkCode=as2&amp;tag=greenteapre01-20">
<img border="0" src="./Scale-free networks_files/q(2)"></a>
<img src="./Scale-free networks_files/ir(2)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491939362/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491939362&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=FJKSQ3IHEMY2F2VA">Think Python 2e</a>
<img src="./Scale-free networks_files/ir(3)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491939362/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491939362&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=ZZ454DLQ3IXDHNHX">
<img border="0" src="./Scale-free networks_files/q(3)"></a>
<img src="./Scale-free networks_files/ir(3)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491907339/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491907339&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=O7WYM6H6YBYUFNWU">Think Stats 2e</a>
<img src="./Scale-free networks_files/ir(4)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491907339/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1491907339&amp;linkCode=as2&amp;tag=greenteapre01-20&amp;linkId=JVSYKQHYSUIEYRHL">
<img border="0" src="./Scale-free networks_files/q(4)"></a>
<img src="./Scale-free networks_files/ir(4)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1449314635/ref=as_li_tf_tl?ie=UTF8&amp;tag=greenteapre01-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1449314635">Think Complexity</a>
<img src="./Scale-free networks_files/ir(5)" width="1" height="1" border="0" alt="" style="border: none !important; margin: 0px !important; display: none !important;">

</p><p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1449314635/ref=as_li_tf_il?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1449314635&amp;linkCode=as2&amp;tag=greenteapre01-20">
<img border="0" src="./Scale-free networks_files/q(5)"></a>
<img src="./Scale-free networks_files/ir(5)" width="1" height="1" border="0" alt="" style="border:none !important; margin:0px !important;">

</p></td>
</tr>
</tbody></table>
<hr>
<a href="http://greenteapress.com/complexity2/html/thinkcomplexity2004.html"><img src="./Scale-free networks_files/back.png" alt="Previous"></a>
<a href="http://greenteapress.com/complexity2/html/index.html"><img src="./Scale-free networks_files/up.png" alt="Up"></a>
<a href="http://greenteapress.com/complexity2/html/thinkcomplexity2006.html"><img src="./Scale-free networks_files/next.png" alt="Next"></a>


</body></html>